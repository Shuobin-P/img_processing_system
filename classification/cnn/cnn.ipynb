{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b70c02",
   "metadata": {},
   "source": [
    "# 教程代码\n",
    "## 问题：不知道Ground Truth数据是什么样子的，教程中展示了Ground Truth的样子，即一张已全部分类的图。但是Ground Truth即y_data在train_test_split()被使用。\n",
    "具体实现：将输入图片分成很多patch，并且每个patch有一个类。 The class label of the patch has been defined as the class of the center pixel of the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import rasterio as rio\n",
    "\n",
    "S_sentinel_bands = glob(\"/content/drive/MyDrive/Satellite_data/sundarbans_data/*B?*.tiff\")\n",
    "S_sentinel_bands.sort()\n",
    "\n",
    "l = []\n",
    "for i in S_sentinel_bands:\n",
    "  with rio.open(i, 'r') as f:\n",
    "    l.append(f.read(1))\n",
    "\n",
    "# Data\n",
    "arr_st = np.stack(l)\n",
    "\n",
    "# Ground Truth\n",
    "y_data = loadmat('Sundarbands_gt.mat')['gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.plot_rgb(\n",
    "    arr_st,\n",
    "    rgb=(3, 2, 1),\n",
    "    stretch=True,\n",
    "    str_clip=0.02,\n",
    "    figsize=(12, 16),\n",
    "    # title=\"RGB Composite Image with Stretch Applied\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Groundtruth\n",
    "\n",
    "ep.plot_bands(y_data, \n",
    "              cmap=ListedColormap(['darkgreen', 'green', 'black', \n",
    "                                   '#CA6F1E', 'navy', 'forestgreen']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d896d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ep.plot_bands(arr_st, \n",
    "              cmap = 'gist_earth', \n",
    "              figsize = (20, 12), \n",
    "              cols = 6, \n",
    "              cbar = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = False):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels\n",
    "\n",
    "def splitTrainTestSet(X, y, testRatio, randomState=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "## GLOBAL VARIABLES\n",
    "dataset = 'SB'\n",
    "test_size = 0.30\n",
    "windowSize = 15\n",
    "MODEL_NAME = 'Sundarbans'\n",
    "path = '/content/drive/MyDrive/Sundarbans/'\n",
    "\n",
    "X_data = np.moveaxis(arr_st, 0, -1)\n",
    "y_data = loadmat('Sundarbands_gt.mat')['gt']\n",
    "\n",
    "# Apply PCA\n",
    "K = 5\n",
    "X,pca = applyPCA(X_data,numComponents=K)\n",
    "\n",
    "print(f'Data After PCA: {X.shape}')\n",
    "\n",
    "# Create 3D Patches\n",
    "X, y = createImageCubes(X, y_data, windowSize=windowSize)\n",
    "print(f'Patch size: {X.shape}')\n",
    "\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = splitTrainTestSet(X, y, testRatio = test_size)\n",
    "\n",
    "X_train = X_train.reshape(-1, windowSize, windowSize, K, 1)\n",
    "X_test = X_test.reshape(-1, windowSize, windowSize, K, 1)\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f'Train: {X_train.shape}\\nTest: {X_test.shape}\\nTrain Labels: {y_train.shape}\\nTest Labels: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = windowSize\n",
    "L = K\n",
    "output_units = y_train.shape[1]\n",
    "\n",
    "## input layer\n",
    "input_layer = Input((S, S, L, 1))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=16, kernel_size=(2, 2, 3), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=32, kernel_size=(2, 2, 3), activation='relu')(conv_layer1)\n",
    "conv2d_shape = conv_layer2.shape\n",
    "conv_layer3 = Reshape((conv2d_shape[1], conv2d_shape[2], conv2d_shape[3]*conv2d_shape[4]))(conv_layer2)\n",
    "conv_layer4 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(conv_layer3)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer4)\n",
    "\n",
    "## fully connected layers\n",
    "dense_layer1 = Dense(128, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(64, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "dense_layer3 = Dense(20, activation='relu')(dense_layer2)\n",
    "dense_layer3 = Dropout(0.4)(dense_layer3)\n",
    "output_layer = Dense(units=output_units, activation='softmax')(dense_layer3)\n",
    "# define the model with input layer and output layer\n",
    "model = Model(name = dataset+'_Model' , inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "logdir = path+\"logs/\" +model.name+'_'+datetime.now().strftime(\"%d:%m:%Y-%H:%M:%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss',\n",
    "                   min_delta = 0,\n",
    "                   patience = 1,\n",
    "                   verbose = 1,\n",
    "                   restore_best_weights = True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = 'Pavia_University_Model.h5', \n",
    "                             monitor = 'val_loss', \n",
    "                             mode ='min', \n",
    "                             save_best_only = True,\n",
    "                             verbose = 1)\n",
    "# Fit\n",
    "history = model.fit(x=X_train, y=y_train, \n",
    "                    batch_size=1024*6, epochs=6, \n",
    "                    validation_data=(X_test, y_test), callbacks = [tensorboard_callback, es, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a41448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(range(len(history['accuracy'].values.tolist())), history['accuracy'].values.tolist(), label = 'Train_Accuracy')\n",
    "plt.plot(range(len(history['loss'].values.tolist())), history['loss'].values.tolist(), label = 'Train_Loss')\n",
    "plt.plot(range(len(history['val_accuracy'].values.tolist())), history['val_accuracy'].values.tolist(), label = 'Test_Accuracy')\n",
    "plt.plot(range(len(history['val_loss'].values.tolist())), history['val_loss'].values.tolist(), label = 'Test_Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test, batch_size=1204*6, verbose=1)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "classes = [f'Class-{i}' for i in range(1, 7)]\n",
    "\n",
    "mat = confusion_matrix(np.argmax(y_test, 1),\n",
    "                            np.argmax(pred, 1))\n",
    "\n",
    "df_cm = pd.DataFrame(mat, index = classes, columns = classes)\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32485a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(np.argmax(y_test, 1),\n",
    "                            np.argmax(pred, 1),\n",
    "      target_names = [f'Class-{i}' for i in range(1, 7)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
